{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3496e44",
   "metadata": {},
   "source": [
    "# Chlengmo Demo\n",
    "\n",
    "## Character-Level N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da06bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/victor/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/victor/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# bloody dependencies\n",
    "# NOTE: The package itself needs no dependencies.\n",
    "#       All of these imports are used in the notebook,\n",
    "#       mostly for downloading & manipulating data.\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"gutenberg\")\n",
    "from nltk.corpus import brown, gutenberg\n",
    "from nltk.lm.models import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# chlengmo\n",
    "from chlengmo import Chlengmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5eb5fa",
   "metadata": {},
   "source": [
    "## Sample Usage: Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432a365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my purse, and nothing\n",
      "particular to interest me on shore, I thought I would sail about a\n",
      "little and see the watery part of the world.  It is a way I have of\n",
      "driving off the spleen and regulating the circulation.  Whenever I\n",
      "find myself growing grim about the mouth; whenever it is a damp,\n",
      "drizzly November in my soul; whenever I find myself involuntarily\n",
      "pausing before coffin warehouses, and bringing up the rear of every\n",
      "funeral I meet; and especially whenever my hypos get such an upper\n",
      "hand of me, that it requires a strong moral principle to prevent me\n",
      "from deliberately stepping into the street, and methodically knocking\n",
      "people's hats off--then, I account it high time to get to sea as soon\n",
      "as I can.  This is my substitute for pistol and ball.  With a\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\n",
      "take to the ship.  There is nothing surprising in this.  If th\n",
      "\n",
      "Fake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no allusion was made to it,\n",
      "especially by night.  On one side,\n",
      "lit by a dull lantern, a space has been left clear for the workmen.\n",
      "They generally are of two\n",
      "sorts; those composed almost entirely\n",
      "different heads.  To sum up, then: in the Right Whale's on the larboard; did you never hear that the ship soon went through\n",
      "the fire;--but now it remains to conclude the chapter with the above appeal, but\n",
      "cannot, owing to my anxiety to repel a charge often made against\n",
      "whalemen, and which, upon the\n",
      "whole, but in all cases did not succeed in his benevolent designs.\n",
      "\n",
      "Now, though such great bodies are at times encountered, at such\n",
      "or such a time, or on such or such a meridian, a Sperm Whale, I have\n",
      "chiefly dwelt upon the marvels of his outer aspect; or separately and\n",
      "in detail upon some few interior structural features.  But to a large\n",
      "and thorough sweeping comprehensiveness than\n",
      "his archa\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus from NLTK\n",
    "filename = \"melville-moby_dick.txt\"\n",
    "text = gutenberg.raw(filename)\n",
    "start = \"Call me Ishmael\"\n",
    "start_idx = text.index(start)\n",
    "text = text[start_idx:]\n",
    "print(\"\\nReal text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 15\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake text\n",
    "length = 981\n",
    "prompt = \"Call me \"\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, prompt=prompt, seed=seed)\n",
    "print(\"\\nFake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d25521",
   "metadata": {},
   "source": [
    "## Sample Usage: Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d80969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "your selfe\n",
      "\n",
      "   Bar. Long liue the King\n",
      "\n",
      "   Fran. Barnardo?\n",
      "  Bar. He\n",
      "\n",
      "   Fran. You come most carefully vpon your houre\n",
      "\n",
      "   Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
      "\n",
      "   Fran. For this releefe much thankes: 'Tis bitter cold,\n",
      "And I am sicke at heart\n",
      "\n",
      "   Barn. Haue you had quiet Guard?\n",
      "  Fran. Not a Mouse stirring\n",
      "\n",
      "   Barn. Well, goodnight. If you do meet Horatio and\n",
      "Marcellus, the Riuals of my Watch, bid them make hast.\n",
      "Enter Horatio and Marcellus.\n",
      "\n",
      "  Fran. I thinke I heare them. Stand: who's there?\n",
      "  Hor. Friends to this ground\n",
      "\n",
      "   Mar. And Leige-men to the Dane\n",
      "\n",
      "   Fran. Giue you good night\n",
      "\n",
      "   Mar. O farwel honest Soldier, who hath relieu'd you?\n",
      "  Fra. Barnardo ha's my place: giue you goodnight.\n",
      "\n",
      "Exit Fran.\n",
      "\n",
      "  Mar. Holla Barnardo\n",
      "\n",
      "   Bar. Say, what is Horatio there?\n",
      "  Hor. A peece o\n",
      "\n",
      "Fake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Hor. Friends to this ground\n",
      "\n",
      "   Mar. And Leige-men to the Dane\n",
      "\n",
      "   Fran. Giue you good night\n",
      "\n",
      "   Mar. O farwel honest Soldier, who hath relieu'd you?\n",
      "  Fra. Barnardo ha's my place: giue you goodnight.\n",
      "\n",
      "Exit Fran.\n",
      "\n",
      "  Mar. Holla Barnardo\n",
      "\n",
      "   Bar. Say, what is Horatio there?\n",
      "  Hor. A peece of him\n",
      "\n",
      "   Bar. Welcome Horatio, welcome good Marcellus\n",
      "\n",
      "   Mar. What, ha's this thing appear'd againe to night\n",
      "\n",
      "   Both. My Lord, from head to foote\n",
      "\n",
      "   Ham. Then are our Beggers bodies; and our Monarchs\n",
      "and out-stretcht Heroes the Beggers Shadowes:\n",
      "shall wee to th' Court: for, by my fey I cannot reason?\n",
      "  Both. Wee'l wait vpon you\n",
      "\n",
      "   Ham. Being thus benetted round with Villaines,\n",
      "Ere I could make a Prologue to my braines,\n",
      "They had begun the Play. I sate me downe,\n",
      "Deuis'd a new Commission, wrote it faire,\n",
      "I once did hold it as our Statists doe,\n",
      "A \n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus from NLTK\n",
    "filename = \"shakespeare-hamlet.txt\"\n",
    "text = gutenberg.raw(filename)\n",
    "print(\"\\nReal text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 15\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake text\n",
    "length = 999\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, seed=seed)\n",
    "print(\"\\nFake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ebfbc",
   "metadata": {},
   "source": [
    "## Sample Usage: King James Bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af67512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep. And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n",
      "\n",
      "1:5 And God called the light Day, and the darkness he called Night.\n",
      "And the evening and the morning were the first day.\n",
      "\n",
      "1:6 And God said, Let there be a firmament in the midst of the waters,\n",
      "and let it divide the waters from the waters.\n",
      "\n",
      "1:7 And God made the firmament, and divided the waters which were\n",
      "under the firmament from the waters which were above the firmament:\n",
      "and it was so.\n",
      "\n",
      "1:8 And God called the firmament Heaven. And the evening and the\n",
      "morning were the second day.\n",
      "\n",
      "1:9 And God said, Let the waters under the heaven be gathered together\n",
      "unto one place, and let the dry land appear: and it was so.\n",
      "\n",
      "1:10 And God called the \n",
      "\n",
      "Fake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "1:1 In the beginning of their dwellings.\n",
      "\n",
      "35:30 Whoso killeth his neighbour: the child shall be a Nazarite unto God from the\n",
      "womb to the day of his cleansing unto\n",
      "the priest, and his\n",
      "sons' garments with him.\n",
      "\n",
      "29:22 Also thou shalt take fine flour, and the lead, 31:23 Every thing that creepeth upon the earth shall be excellent and comely for\n",
      "them that are numbered, from twenty years old this\n",
      "day; I can no more go out and come in: also the LORD sitteth King for\n",
      "ever.\n",
      "\n",
      "29:11 Thine, O LORD is the greatness of thine\n",
      "arm they shall be my people.\n",
      "\n",
      "6:17 Wherein God, willing to shew the Jews a pleasure, left Paul bound.\n",
      "\n",
      "25:1 Now when Festus was come into the land of Canaan; 45:18 And\n",
      "take your fathers hearkened not unto me, nor to come near by their\n",
      "families, by the house of their father's house; for he was\n",
      "yet there: and there was a sore\n",
      "famine in Samaria.\n",
      "\n",
      "18:3 And Ahab king of Israel\n",
      "came and cried unto my God: he\n",
      "heard my voice out of the camp to meet with\n",
      "God; and they shall trust in the Lord Jesus Christ, p\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus from NLTK\n",
    "filename = \"bible-kjv.txt\"\n",
    "text = gutenberg.raw(filename)\n",
    "start = \"1:1 In the beginning \"\n",
    "start_idx = text.index(start)\n",
    "text = text[start_idx:]\n",
    "print(\"\\nReal text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 15\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake text\n",
    "length = 999\n",
    "prompt = \"1:1 In the beginning \"\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, prompt=prompt, seed=seed)\n",
    "print(\"\\nFake text >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1c4d9",
   "metadata": {},
   "source": [
    "## Sample Usage: Trump Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fbec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real tweets >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "RT @ScottAdamsSays: Malaria drug and zinc the missing link https://t.co/FC9CpuH0Yr via @theconwom\n",
      "\n",
      "RT @YoungDems4Trump: In Democrat cities you can get arrested for opening a business but not for looting one. #MinneapolisRiot #Coronavirus\n",
      "\n",
      "RT @YoungDems4Trump: So sad. This poor business owner lost everything due to the  #MinneapolisRiothttps://t.co/mK0nHFNthS\n",
      "\n",
      "Time for a change! #2020 https://t.co/AECy2GBfys\n",
      "\n",
      "RT @TallahForTrump: Trump spoke at my church in Detroit and it opened my eyes. Never again will I be a slave to the Democrats!👊 Let us rise…\n",
      "\n",
      "RT @TheRightMelissa: In an ironic twist of fate CNN HQ is being attacked by the very riots they promoted as noble &amp; just. Oops\n",
      "\n",
      "RT @Jim_Jordan: Right on! We don’t have to pay organizations to lie to us. They’ll probably do it for free.\n",
      "\n",
      "RT @Scavino45: “Texas AG Ken Paxton: Trump is right and Twitter ‘fact check’ is wrong – mail-in ballot fraud is a real problem” https://t.c…\n",
      "\n",
      "RT @Jim_Jordan: Twitter “fact checks” President Trump. Did the\n",
      "\n",
      "Fake tweets >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Hillary Clinton is not Presidential Medal of Freedom. Considering the recipients history and the poverty index is also best number EVER) leagues and teams love coming to the conclusion the fact that I wanted a Moot stuffed with alligators and snakes with an electrified fence and sharp spikes on top at our Southern Border. This is being done to greatly reduce or eliminate every obstacle necessary…\n",
      "\n",
      "RT @realDonaldTrump holds a Cabinet meeting at the United Nations General Keane on receiving our Nation’s proud heritage. It is the cornerstone of our Freedom. It is what guarantees equal justice -…\n",
      "\n",
      "RT @Scavino45: A MESSAGE FROM @StateDept @SecPompeo outside of the No Collusion (except by Crooked Hillary Clinton 2015.\n",
      "\n",
      "https://t.co/CR4I8dvunc\n",
      "\n",
      "China is very good. We are the envy of the world!\n",
      "\n",
      "Great job by Michael Anton on @foxandfriends: .@jasoninthehouse: Great interview.  I wonder who did an unmasking the morning speaking to @fema and Military he loves our Vets! Adrian has my Complete and Total Endorsement\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "filename = \"https://raw.githubusercontent.com/ecdedios/into-heart-of-darkness/master/trump_20200530.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "text = \"\\n\\n\".join(df[\"text\"].values)\n",
    "print(\"\\nReal tweets >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 15\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake tweets\n",
    "length = 999\n",
    "prompt = \"Hillary Clinton is \"\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, prompt=prompt, seed=seed)\n",
    "print(\"\\nFake tweets >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76847dac",
   "metadata": {},
   "source": [
    "## Sample Usage: Prime Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a818cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real primes >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97 101 103 107 109 113 121 127 131 137 139 143 149 151 157 163 167 169 173 179 181 187 191 193 197 199 209 211 221 223 227 229 233 239 241 247 251 253 257 263 269 271 277 281 283 289 293 299 307 311 313 317 319 323 331 337 341 347 349 353 359 361 367 373 377 379 383 389 391 397 401 403 407 409 419 421 431 433 437 439 443 449 451 457 461 463 467 473 479 481 487 491 493 499 503 509 517 521 523 527 529 533 541 547 551 557 559 563 569 571 577 583 587 589 593 599 601 607 611 613 617 619 629 631 641 643 647 649 653 659 661 667 671 673 677 683 689 691 697 701 703 709 713 719 727 731 733 737 739 743 751 757 761 767 769 773 779 781 787 793 797 799 803 809 811 817 821 823 827 829 839 841 851 853 857 859 863 869 871 877 881 883 887 893 899 901 907 911 913 919 923 929 937 941 943 947 949 953 961 967 971 977 979 983 989 991 997 1003 1007 1009 1013 1019 1021 1027 1031 1033 1037 1039 1049 1051 1061 1063 1067 1069 1073 1079 1081 1087\n",
      "\n",
      "Fake primes >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "2 3 5 7 11 13 673 5587 7367 663147463 897 2586903193599 337 7353 1304479 90591651 3338833 843 63683 867 7523 906027131 61498817 88331 5629 370821 2077 52171 24319 3053 1391 1751227 531897421 9445607 983 443 8489 8808277 9790143 80667 86657176187 653 8364317819 959 574007 30883 2250479 601 76319 634827 3724191 7788969 1905221 72833 8802879 888214752169 237 38013 86070181 92917 632729993 759 229 943 90589 473 6543 4021 4594541 73427 6159 67257 1067 2426040244969259 35293 733 41339 9641 865253 928039 633 7953 4157 67577 9399 583 7603333981 1159 52119 201 35039 551969 829 96962784263901497 538275171 781 29861 8729933747 59697 5921 11179 14209 713 763093 24897 170963 6711 8124517 980337981 611 7461 524685468313227 3261 55097 749 70892061 54581137 995233 8869 3049049 1924511833 853 467089 2429 2031 86881438961 6047 9663 15619 52833609 46823779 61403316223 5287 60053 68468741 16651 253277 378861 9653 2197 660109 652717214433339364843 627 51110925169453 8102600233 44569607 78681 209 1097 21465039 974387 90\n"
     ]
    }
   ],
   "source": [
    "# sieve of erotasthenes\n",
    "maxprime = 1000000\n",
    "isprime = [True] * maxprime\n",
    "isprime[0] = False\n",
    "isprime[1] = False\n",
    "for factor in range(2, 11):\n",
    "    multiple = 2 * factor\n",
    "    while multiple < maxprime:\n",
    "        isprime[multiple] = False\n",
    "        multiple += factor\n",
    "primes = [number for number, flag in enumerate(isprime) if flag]\n",
    "text = \" \".join([str(prime) for prime in primes])\n",
    "print(\"\\nReal primes >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 4\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake primes\n",
    "length = 999\n",
    "prompt = \"2 3 5 7 11 13 \"\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, prompt=prompt, seed=seed)\n",
    "print(\"\\nFake primes >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05afbedf",
   "metadata": {},
   "source": [
    "## Sample Usage: News Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ad3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real news >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted . The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. . `` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' . The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' . It recommended that Fulton legislators act `` to have t\n",
      "\n",
      "Fake news >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Fulton County Grand Jury said Friday an investigation by Detective William Taylor and other officials of the city and the other doesn't want to give up any '' . Battle in the senate The Senate launched the 87th Congress with its own version of an ancient liberal-conservative barriers around the Rules Committee in moving bills to the floor . The liberals , smelling blood , were faced with more of the same . These , however , was derived from the reactor of the more modern American nuclear submarine Skipjack . Five held for trial The announcement last week of the forthcoming encounter produced strong reactions in the U. S. of both approval and disapproval . The approval did not arise from an expectation of far-reaching reforms '' which would be a savings of $157,460 yearly after the first year's capital outlay of $88,000 was absorbed , Parkhouse told the Senate . The TEA estimated the combined programs would cost 5.1 million dollars the first year , 1963 . Both figures would go higher in later years . Other parts of the co\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus from NLTK\n",
    "words = brown.words(categories=\"news\")\n",
    "text = \" \".join(words)\n",
    "print(\"\\nReal news >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(text[:999])\n",
    "\n",
    "# create and fit model\n",
    "n = 15\n",
    "model = Chlengmo(n=n).fit(text)\n",
    "\n",
    "# generate fake text\n",
    "length = 999\n",
    "prompt = \"The Fulton County Grand Jury said Friday \"\n",
    "seed = 42\n",
    "fake_text = model.generate(length=length, prompt=prompt, seed=seed)\n",
    "print(\"\\nFake news >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "print(fake_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94096211",
   "metadata": {},
   "source": [
    "## Speed Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3833149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Chlengmo model in 0.29s\n",
      "Fit NLTK model in 8.23s\n",
      "Fit Chlengmo model 28x faster than NLTK model.\n",
      "Generated text from Chlengmo model in 0.03s\n",
      "Generated text from NLTK model in 1.00s\n",
      "Generated text from Chlengmo model 37x faster than NLTK model.\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus from NLTK\n",
    "filename = \"melville-moby_dick.txt\"\n",
    "text = gutenberg.raw(filename)\n",
    "start = \"Call me Ishmael\"\n",
    "start_idx = text.index(start)\n",
    "text = text[start_idx:]\n",
    "\n",
    "# fit chlengmo model\n",
    "n = 3\n",
    "chlengmo = Chlengmo(n=n)\n",
    "time_start = time.process_time()\n",
    "chlengmo.fit(text)\n",
    "time_end = time.process_time()\n",
    "time_elapsed_chlengmo = time_end - time_start\n",
    "print(f\"Fit Chlengmo model in {time_elapsed_chlengmo:.2f}s\")\n",
    "\n",
    "# fit nltk model\n",
    "# REF: https://www.nltk.org/api/nltk.lm.html\n",
    "train, vocab = padded_everygram_pipeline(n, [list(text)])\n",
    "mle = MLE(n)\n",
    "time_start = time.process_time()\n",
    "mle.fit(train, vocab)\n",
    "time_end = time.process_time()\n",
    "time_elapsed_nltk = time_end - time_start\n",
    "print(f\"Fit NLTK model in {time_elapsed_nltk:.2f}s\")\n",
    "\n",
    "# chlengmo is >10x faster!\n",
    "time_factor = time_elapsed_nltk / time_elapsed_chlengmo\n",
    "print(f\"Fit Chlengmo model {time_factor:.0f}x faster than NLTK model.\")\n",
    "\n",
    "# generate fake text from chlengmo model\n",
    "length = 9999\n",
    "prompt = \"Call me \"\n",
    "time_start = time.process_time()\n",
    "fake_text_chlengmo = chlengmo.generate(length=length, prompt=prompt)\n",
    "time_end = time.process_time()\n",
    "time_elapsed_chlengmo = time_end - time_start\n",
    "print(f\"Generated text from Chlengmo model in {time_elapsed_chlengmo:.2f}s\")\n",
    "\n",
    "# generate fake text from nltk model\n",
    "time_start = time.process_time()\n",
    "fake_text_nltk = mle.generate(num_words=length, text_seed=list(prompt))\n",
    "time_end = time.process_time()\n",
    "time_elapsed_nltk = time_end - time_start\n",
    "fake_text_nltk = \"\".join(fake_text_nltk)\n",
    "print(f\"Generated text from NLTK model in {time_elapsed_nltk:.2f}s\")\n",
    "\n",
    "# chlengmo is >10x faster!\n",
    "time_factor = time_elapsed_nltk / time_elapsed_chlengmo\n",
    "print(f\"Generated text from Chlengmo model {time_factor:.0f}x faster than NLTK model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
